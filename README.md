Перемножение матриц с помощью технологии CUDA
=====================


**Характеристики компьютера: <br />**
***Операционная система:*** Windows 10 Home Single Language, 64-bit; <br /> 
***Процессор (CPU):*** Intel (R) Core (TM) i5-8250U CPU @ 1,60GHz; <br />
***Оперативная память:*** 4096 МБ; <br />
***Видеокарта (CUDA Device):*** NVIDIA GeForce MX110; <br />
***Количество ядер CUDA:*** 256; <br />
***Архитектура видеокарты:*** Maxwell; <br />
***Версия CUDA:*** 10.2.89. <br />

Код программы содержит две основные функции: GPU_matMul - функция (ядро) умножения матриц на GPU и CPU_matMul - на CPU, а также функцию проверки правильности результата. <br />
GPU_matMul принимает 3 параметра: две матрицы, которые необходимо умножить и результат умножения этих матриц.
Используя встроенную библиотеку CUDA SDK, выделим память на device (с помощью фуннции cudaMalloc).
Далее копируем данные, сгенерированные на хосте, на устройство, используя функцию cudaMemcpy. Последний параметр в ней принимает значение cudaMemcpyHostToDevice.
Для определения времени установим точку старта работы программы на GPU, используя функцию cudaEventRecord (start, 0);
Значение BLOCK_SIZE является значением количество нитей в блоках. Возьмем его равным 16.
Матрицы размера N делятся на подматрицы размером 16 на 16 и такими блоками загружались в блоки нитей (GRID_SIZE).
Далее произведём запуск ядра GPU_matMul.
Вычисленную на GPU результирующую матрицу C скопируем на host, используя функцию cudaMemcpy. Последний параметр в ней принимает значение cudaMemcpyDeviceToHost.
В конце проведём освобождение памяти.
Также, используя встроенную библиотеку, будем обрабатывать различные ошибки при работе с CUDA.<br />

Сравним время работы и ускорение последовательного и параллельного алгоритмов:

N | 128 | 256 | 512 | 768 | 1024 | 
--- | --- | --- | --- |--- |--- |
CPU, ms | 11 | 101 | 991 | 3334 | 10706 | 
GPU, ms | 3 | 21 | 161 | 539 | 1267 | 
Ускорение | 3,67 | 4,81 | 6,16 | 6,19 | 8,45 | 

Анализируя таблицу, можно сделать вывод, что время очень существенно увеличивается при увеличении размера матрицы на CPU. А на GPU время возрастает намного медленее. При больших размерах матриц CUDA даёт существенное ускорение, поэтому рациональней распараллеливать матрицы больших размеров.
